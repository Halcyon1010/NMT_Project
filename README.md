# Chineseâ€“English Neural Machine Translation (NMT) Project

This project is a **Chinese-to-English (Zhâ€“En) Neural Machine Translation system** implemented with **PyTorch**.  
It provides a comprehensive pipeline covering **RNN-based models, Transformer models, and fine-tuning of pretrained models (NLLB)**, with the goal of systematically comparing different architectures on machine translation tasks.

---

## ğŸ“‹ Project Overview

This repository implements three mainstream NMT solutions and provides unified interfaces for data preprocessing, training, inference, and evaluation, enabling fair and convenient comparisons across models.

### 1. RNN (Seq2Seq + Attention)
- Encoderâ€“decoder architecture based on **GRU**
- Implements **Luong Attention**, supporting `dot`, `general`, and `concat` variants
- Supports **Teacher Forcing** during training

### 2. Transformer
- Standard Transformer architecture proposed in *Attention Is All You Need*
- **Ablation-friendly design**, supporting:
  - Normalization layers: `LayerNorm` vs. `RMSNorm`
  - Positional encodings: `Sinusoidal` vs. `Learnable`

### 3. NLLB (Fine-tuning)
- Fine-tuning of Metaâ€™s **No Language Left Behind (NLLB)** pretrained model
- Model used: `facebook/nllb-200-distilled-600M`
- Implemented using the Hugging Face `transformers` library

---

## âš™ï¸ Environment Setup

```bash
conda create -n NMT python=3.10.0
conda activate NMT

pip install -r requirements.txt
```

**Note**:
At the first run, the scripts will automatically download the NLTK `punkt` tokenizer data and cache it in the `nltk_data/` directory.


## ğŸ“Š Data Preparation

The project uses datasets in JSONL (JSON Lines) format.
Please prepare the following files under the `data/` directory:

- `train_100k.jsonl` â€” training set

- `valid.jsonl` â€” validation set

- `test.jsonl` â€” test set

### Data Format

Each line corresponds to a single JSON object and must contain the following fields:

- `zh`: source sentence in Chinese

- `en`: target sentence in English

### Example
```json
{"zh": "æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†ã€‚", "en": "I love Natural Language Processing."}
{"zh": "æ·±åº¦å­¦ä¹ æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚", "en": "Deep learning is changing the world."}
```

## ğŸš€ Quick Start

**Note**:
Please adjust path-related arguments (e.g., `--data_root`) according to your local directory structure.

### 1. Train an RNN Model (Seq2Seq + Attention)

Train a two-layer GRU model with Luong Attention (General):
```bash
python train_RNN.py \
  --data_root ./data \
  --save_path ./results \
  --exp RNN_Luong_general \
  --hidden_size 512 \
  --n_layers 2 \
  --attn_method general \
  --batch_size 240 \
  --epochs 50 \
  --lr 8e-4
```

### 2. Train a Transformer Model

Train a standard Transformer model using learnable positional encoding and LayerNorm:
```bash
python train_transformer.py \
  --data_root ./data \
  --save_path ./results \
  --exp Transformer_base \
  --d_model 512 \
  --n_head 8 \
  --n_layers 6 \
  --ffn_dim 2048 \
  --norm_type layernorm \
  --pos_type learnable \
  --batch_size 120 \
  --epochs 50
```
### 3. Fine-tune the NLLB Model

Fine-tune `facebook/nllb-200-distilled-600M` using Hugging Face `transformers`:
```bash
python Finetune_NLLB.py \
  --data_root ./data \
  --output_dir ./results/nllb_finetuned \
  --model_name_or_path facebook/nllb-200-distilled-600M \
  --train_file train_100k.jsonl \
  --valid_file valid.jsonl \
  --per_device_train_batch_size 32 \
  --gradient_accumulation_steps 4 \
  --num_train_epochs 3 \
  --learning_rate 1e-4
```
**Tip**:
If GPU memory is limited, reduce `per_device_train_batch_size` and increase `gradient_accumulation_steps` accordingly.


## ğŸ” Inference & Evaluation
### Unified Evaluation Script (`inference.py`)

This is the recommended evaluation entry point.
It supports loading multiple models simultaneously and computes **BLEU** and **BERTScore** on the test set.

```bash
python inference.py \
  --data_root ./data \
  --test_file test.jsonl \
  --save_path ./inference_results \
  --models rnn transformer nllb \
  --rnn_ckpt ./results/RNN_Luong_general/best_model.pth \
  --trans_ckpt ./results/Transformer_base/best_model.pth \
  --nllb_path ./results/nllb_finetuned/final \
  --batch_size 100 \
  --beam_width 5 \
  --device cuda

```

### Single-Model Testing

If you only want to evaluate a single model, use the corresponding test script:

**RNN**
```bash
python test_RNN.py \
  --resume ./results/RNN_Luong_general/best_model.pth \
  --decode beam \
  --beam_width 5
```

**Transformer**
```bash
python test_transformer.py \
  --resume ./results/Transformer_base/best_model.pth \
  --decode beam \
  --beam_width 5

```

**NLLB**
```bash
python test_NLLB.py \
  --model_path ./results/nllb_finetuned/final
```

## ğŸ›  Technical Details
### Text Processing

Chinese tokenization: `jieba`

English tokenization: `nltk.word_tokenize`

Vocabulary: Automatically built and saved as `.pth` files, supporting special tokens
`<pad>`, `<sos>`, `<eos>`, `<unk>`

### Decoding Strategies

Greedy Search

Beam Search, with length penalty support and batch-parallel decoding for faster inference

### Evaluation Metrics

**BLEU**: Corpus-level BLEU score computed with `sacrebleu`

**BERTScore**: Semantic similarity computed using a pretrained BERT model

**PPL (Perplexity)**: Measures the predictive uncertainty of the language model

## ğŸ“‚ Project Structure

```text
NMT_Project/
â”œâ”€â”€ data/                   # Datasets (JSONL format)
â”‚   â”œâ”€â”€ train_100k.jsonl
â”‚   â”œâ”€â”€ valid.jsonl
â”‚   â””â”€â”€ test.jsonl
â”œâ”€â”€ nltk_data/              # Cached NLTK resources
â”œâ”€â”€ results/                # Saved models and  experimental outputs
â”œâ”€â”€ Finetune_NLLB.py        # NLLB fine-tuning script
â”œâ”€â”€ inference.py            # Unified inference & evaluation script
â”œâ”€â”€ nlp_dataset.py          # Data preprocessing and Dataset definitions
â”œâ”€â”€ RNN.py                  # RNN model definitions
â”œâ”€â”€ Transformer.py          # Transformer model definitions
â”œâ”€â”€ train_RNN.py            # RNN training script
â”œâ”€â”€ train_transformer.py    # Transformer training script
â”œâ”€â”€ test_RNN.py             # RNN testing script
â”œâ”€â”€ test_transformer.py     # Transformer testing script
â”œâ”€â”€ test_NLLB.py            # NLLB testing script
â””â”€â”€ utils.py                # Utilities (Beam Search, metrics, logging)
```